{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd7468a",
   "metadata": {},
   "source": [
    "# Laboratorio: Aprendizaje Supervisado\n",
    "\n",
    "### Integrantes:\n",
    "### Javier Benitez 23405, Javier Lopéz \n",
    "\n",
    "\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e70bf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "housing_data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "df = housing_data.frame\n",
    "X = housing_data.data\n",
    "y = housing_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2bb5d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude   MedHouseVal  \n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704      2.068558  \n",
      "std       10.386050      2.135952      2.003532      1.153956  \n",
      "min        0.692308     32.540000   -124.350000      0.149990  \n",
      "25%        2.429741     33.930000   -121.800000      1.196000  \n",
      "50%        2.818116     34.260000   -118.490000      1.797000  \n",
      "75%        3.282261     37.710000   -118.010000      2.647250  \n",
      "max     1243.333333     41.950000   -114.310000      5.000010  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dee0eb",
   "metadata": {},
   "source": [
    "## Breve Analisis\n",
    "\n",
    "La variable objetivo es MedHouseVal y se puede ver que los datos estan bastante agrupados a que tienen un std cercano a 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21d243ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de datos: 20640\n",
      "Entrenamiento: 16512\n",
      "Prueba: 4128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "print(f\"Total de datos: {len(X)}\")\n",
    "print(f\"Entrenamiento: {len(X_train)}\")\n",
    "print(f\"Prueba: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb10fc6",
   "metadata": {},
   "source": [
    "## Justificar los valores usados para test_size y random_state.\n",
    "\n",
    "Se uso el 20% ya que es el valor \"optimo\" de datos segun la regla de pareto que el 80% de los resultados vienen de el primer 20% y si usamos mas datos como el 50% se estarian desperdiciando datos valiosos que el modelo nececita para aprender.\n",
    "\n",
    "Y para el random state ya que actua como una \"semilla\" para la reproducibilidad de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "639d74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando regresion linear\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf24f8",
   "metadata": {},
   "source": [
    "## Utilizando MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca88954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5313679167350401\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babfea20",
   "metadata": {},
   "source": [
    "## Utilizando MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e1f5eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5278524621633068\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091e90c",
   "metadata": {},
   "source": [
    "## Utilizando RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1a2c759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5278524621633068\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a2363",
   "metadata": {},
   "source": [
    "## R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc456368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.6075494500520068\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5f028",
   "metadata": {},
   "source": [
    "## Optimizacion de Hiperparámetros\n",
    "Usando GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d24e778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Mejor puntuación (R2): 0.8053803164663019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modelo = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo, \n",
    "    param_grid=param_grid, \n",
    "    cv=5,              \n",
    "    scoring='r2',      \n",
    "    n_jobs=6         \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación (R2): {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104309c1",
   "metadata": {},
   "source": [
    "## Justificar la elección del método de búsqueda y del esquema de validación cruzada\n",
    "\n",
    "Se optó por GridSearchCV debido a que el espacio de búsqueda de hiperparámetros es manejable y se busca garantizar el hallazgo de la combinación óptima de forma exhaustiva.\n",
    "\n",
    "para asegurar que los parámetros seleccionados no dependan de una partición al azar de los datos se opto por el esquema validación cruzada de 5 pliegues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8cd6c",
   "metadata": {},
   "source": [
    "# Problema de Clasificación Binaria\n",
    "##### Breast Cancer Wisconsin Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd2089c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluación\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Optimización\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940c00e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87442c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ada874",
   "metadata": {},
   "source": [
    "### Exploración de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16e7769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7a8aa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80d876",
   "metadata": {},
   "source": [
    "#### Balanceo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a29a9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68736ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    0.627417\n",
       "0    0.372583\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090be32",
   "metadata": {},
   "source": [
    "### Separación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfbebdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b998d0",
   "metadata": {},
   "source": [
    "#### Escalamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb123cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169a440",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "631a29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b91575c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93d0678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a30cac",
   "metadata": {},
   "source": [
    "### Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "262f001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    print(f\"--- {model_name} ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1-score:\", f1_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a400e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9861111111111112\n",
      "Recall: 0.9861111111111112\n",
      "F1-score: 0.9861111111111112\n",
      "Confusion Matrix:\n",
      " [[41  1]\n",
      " [ 1 71]]\n",
      "\n",
      "\n",
      "--- kNN ---\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9722222222222222\n",
      "F1-score: 0.9655172413793104\n",
      "Confusion Matrix:\n",
      " [[39  3]\n",
      " [ 2 70]]\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9722222222222222\n",
      "F1-score: 0.9655172413793104\n",
      "Confusion Matrix:\n",
      " [[39  3]\n",
      " [ 2 70]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_knn, \"kNN\")\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9297b",
   "metadata": {},
   "source": [
    "## Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34fa3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    LogisticRegression(max_iter=10000),\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "grid_lr.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20983755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Optimized ---\n",
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9726027397260274\n",
      "Recall: 0.9861111111111112\n",
      "F1-score: 0.9793103448275862\n",
      "Confusion Matrix:\n",
      " [[40  2]\n",
      " [ 1 71]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lr = grid_lr.best_estimator_\n",
    "y_pred_lr_opt = best_lr.predict(X_test_scaled)\n",
    "\n",
    "evaluate_model(y_test, y_pred_lr_opt, \"Logistic Regression Optimized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3838e1",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0af41da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid_knn,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89e55e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- kNN Optimized ---\n",
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.972972972972973\n",
      "Recall: 1.0\n",
      "F1-score: 0.9863013698630136\n",
      "Confusion Matrix:\n",
      " [[40  2]\n",
      " [ 0 72]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn = grid_knn.best_estimator_\n",
    "y_pred_knn_opt = best_knn.predict(X_test_scaled)\n",
    "\n",
    "evaluate_model(y_test, y_pred_knn_opt, \"kNN Optimized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f997e",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f54154e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f048d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest Optimized ---\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9722222222222222\n",
      "F1-score: 0.9655172413793104\n",
      "Confusion Matrix:\n",
      " [[39  3]\n",
      " [ 2 70]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf_opt = best_rf.predict(X_test)\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf_opt, \"Random Forest Optimized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70537d59",
   "metadata": {},
   "source": [
    "## Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48b14d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal dimension error</td>\n",
       "      <td>0.229461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness error</td>\n",
       "      <td>0.227123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean fractal dimension</td>\n",
       "      <td>0.214020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry error</td>\n",
       "      <td>0.150838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity error</td>\n",
       "      <td>0.078932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Coefficient\n",
       "19  fractal dimension error     0.229461\n",
       "15        compactness error     0.227123\n",
       "9    mean fractal dimension     0.214020\n",
       "18           symmetry error     0.150838\n",
       "16          concavity error     0.078932"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': best_lr.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "coef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51a3a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst area</td>\n",
       "      <td>0.147168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst concave points</td>\n",
       "      <td>0.135973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst radius</td>\n",
       "      <td>0.103521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean concave points</td>\n",
       "      <td>0.101476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst perimeter</td>\n",
       "      <td>0.075447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Importance\n",
       "23            worst area    0.147168\n",
       "27  worst concave points    0.135973\n",
       "20          worst radius    0.103521\n",
       "7    mean concave points    0.101476\n",
       "22       worst perimeter    0.075447"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importances.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71afd036",
   "metadata": {},
   "source": [
    "# Reflexión Final del Laboratorio\n",
    "\n",
    "En este laboratorio trabajamos un problema real de clasificación binaria utilizando el dataset Breast Cancer Wisconsin. El objetivo fue entrenar distintos modelos de Machine Learning para predecir si un tumor es benigno o maligno, y analizar cuál de ellos funciona mejor considerando no solo el rendimiento numérico, sino también el impacto de los errores.\n",
    "\n",
    "Primero exploramos el dataset para entender su estructura y verificar el balance de clases. Luego se dividieron los datos en entrenamiento y prueba, asegurando que ambas particiones mantuvieran la misma proporción de clases. También se aplicó escalamiento a los modelos que lo necesitaban (Regresión Logística y kNN), ya que estos dependen de la magnitud de las variables.\n",
    "\n",
    "Después se entrenaron tres modelos:\n",
    "\n",
    "- Regresión Logística  \n",
    "- k-Nearest Neighbors (kNN)  \n",
    "- Random Forest  \n",
    "\n",
    "El entrenamiento consistió en permitir que cada modelo aprendiera patrones a partir de los datos de entrenamiento usando `.fit()`. Posteriormente se evaluaron en el conjunto de prueba utilizando métricas como Accuracy, Precision, Recall y F1-score.\n",
    "\n",
    "Sin embargo, no nos quedamos solo con los valores por defecto. Se realizó una optimización de hiperparámetros usando GridSearchCV, probando diferentes configuraciones para encontrar la combinación que mejor desempeño ofreciera según el F1-score.\n",
    "\n",
    "---\n",
    "\n",
    "## Modelo con Mejor Desempeño\n",
    "\n",
    "El modelo que obtuvo mejores resultados fue **kNN optimizado**, con:\n",
    "\n",
    "- Accuracy: 0.9824  \n",
    "- Precision: 0.9729  \n",
    "- Recall: 1.0  \n",
    "- F1-score: 0.9863  \n",
    "\n",
    "Lo más importante es que logró **cero falsos negativos**.\n",
    "\n",
    "En un problema médico como este, el error más grave es clasificar un tumor maligno como benigno. Ese tipo de error puede retrasar tratamiento y tener consecuencias muy serias. Por eso, más allá de la accuracy, el recall se vuelve una métrica clave.\n",
    "\n",
    "El hecho de que el modelo tenga recall = 1.0 significa que detectó correctamente todos los casos positivos del conjunto de prueba.\n",
    "\n",
    "---\n",
    "\n",
    "## Sobre los Hiperparámetros\n",
    "\n",
    "Durante la optimización se ajustaron distintos hiperparámetros:\n",
    "\n",
    "- En Regresión Logística se ajustó el nivel de regularización.\n",
    "- En kNN se probó con diferentes números de vecinos, tipos de ponderación y métricas de distancia.\n",
    "- En Random Forest se ajustaron el número de árboles y su profundidad.\n",
    "\n",
    "Los hiperparámetros influyen directamente en qué tan complejo o flexible es el modelo. Si el modelo es demasiado flexible puede sobreajustar; si es demasiado simple puede no capturar bien los patrones.\n",
    "\n",
    "La optimización permitió encontrar un equilibrio adecuado, especialmente en el caso de kNN.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparación General\n",
    "\n",
    "| Modelo | Accuracy | Precision | Recall | F1-score |\n",
    "|--------|----------|-----------|--------|----------|\n",
    "| Logistic Regression | 0.9824 | 0.9861 | 0.9861 | 0.9861 |\n",
    "| kNN | 0.9561 | 0.9589 | 0.9722 | 0.9655 |\n",
    "| Random Forest | 0.9561 | 0.9589 | 0.9722 | 0.9655 |\n",
    "| Logistic Regression (Opt) | 0.9737 | 0.9726 | 0.9861 | 0.9793 |\n",
    "| kNN (Opt) | 0.9824 | 0.9729 | 1.0 | 0.9863 |\n",
    "| Random Forest (Opt) | 0.9561 | 0.9589 | 0.9722 | 0.9655 |\n",
    "\n",
    "Aunque varios modelos tuvieron resultados muy buenos, kNN optimizado fue el que mejor equilibró precisión y sensibilidad.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Este laboratorio no fue solo sobre entrenar modelos, sino sobre entender cómo evaluarlos correctamente y cómo elegir el más adecuado según el contexto del problema.\n",
    "\n",
    "Aprendimos que:\n",
    "\n",
    "- Optimizar hiperparámetros puede marcar una gran diferencia.\n",
    "- No siempre el modelo más complejo es el mejor.\n",
    "- Las métricas deben elegirse según el impacto real del error.\n",
    "- En aplicaciones médicas, minimizar falsos negativos es prioritario.\n",
    "\n",
    "En general, este ejercicio permitió aplicar todo el flujo de un problema de Machine Learning supervisado, desde la exploración hasta el análisis crítico de resultados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
